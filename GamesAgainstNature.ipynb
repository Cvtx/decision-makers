{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Numerical solution of games against nature under uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game Against Nature\n",
    "\n",
    "A Game Against Nature is a 1-player game, in which a single rational self-interested player must choose a strategy, and the outcome and the player’s payoff depends on both his chosen strategy and the “choice” made by a totally disinterested nature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Payoff matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Player has $m$ allowed types of actions (strategies), and nature can take $n$ different states. If the player chooses the strategy $i\\space (i\\in\\overline{1,m})$, and nature turns out to be in the state $j\\space (j\\in\\overline{1,n})$, then the player receives payoff $p_{ij}$. A payoff matrix is set up as a crosstabulation of player strategies and nature’s contingencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P = \\left(\\begin{array}{cc} \n",
    "p_{11} & p_{12} & \\dots & P_{1j} & \\dots & p_{1n} \\\\\n",
    "p_{21} & p_{22} & \\dots & p_{2j} & \\dots & p_{2n} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "p_{i1} & p_{i2} & \\dots & p_{ij} & \\dots & p_{in} \\\\\n",
    "p_{m1} & p_{m2} & \\dots & p_{mj} & \\dots & p_{mn} \\\\\n",
    "\\end{array}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost matrix is similar to the payoff matrix but it contains costs instead of payoffs. Almost always the player wants to minimize costs or maximize payoffs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "C = \\left(\\begin{array}{cc} \n",
    "c_{11} & c_{12} & \\dots & c_{1j} & \\dots & c_{1n} \\\\\n",
    "c_{21} & c_{22} & \\dots & c_{2j} & \\dots & a_{2n} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "c_{i1} & c_{i2} & \\dots & c_{ij} & \\dots & c_{in} \\\\\n",
    "c_{m1} & c_{m2} & \\dots & c_{mj} & \\dots & c_{mn} \\\\\n",
    "\\end{array}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regret matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regret matrix may be associated with a payoff or cost matrix. Let's assume nature take some state of $j$ (the $j$ column of payoffs or costs has been realized). In this situation, the player can choose one of his strategies, which is equivalent to choosing a certain row $i$.\n",
    "\n",
    "In case of a payoff matrix there is a maximum among them $\\alpha_j = \\underset{i=1,\\dots,m}{max} p_{ij}$. \n",
    "If the player selects a row other than the row of the maximum element, the payoff will be less, and the regret of the payoff can be calculated as the difference $r_{ij} = \\alpha_j − p_{ij}$.\n",
    "\n",
    "In case of a cost matrix there is a minimum among them $\\beta_j = \\underset{i=1,\\dots,m}{min} c_{ij}$. \n",
    "If the player selects a row other than the row of the minimum element, the cost will be more, and the regret of the cost can be calculated as the difference $r_{ij} = c_{ij} - \\beta_j$. \n",
    "\n",
    "The values of $r_{ij}$ are called regrets. A regret matrix is formed from them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "R = \\left(\\begin{array}{cc} \n",
    "r_{11} & r_{12} & \\dots & r_{1j} & \\dots & r_{1n} \\\\\n",
    "r_{21} & r_{22} & \\dots & r_{2j} & \\dots & r_{2n} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "r_{i1} & r_{i2} & \\dots & r_{ij} & \\dots & r_{in} \\\\\n",
    "r_{m1} & r_{m2} & \\dots & r_{mj} & \\dots & r_{mn} \\\\\n",
    "\\end{array}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "# install missing imports\n",
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "import random\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from abc import ABC, abstractmethod\n",
    "from IPython.display import display, Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game():\n",
    "    def __init__(self):\n",
    "        self._generate_random_game()\n",
    "        self._generate_game_data()\n",
    "    \n",
    "    def _generate_costs(self):\n",
    "        return np.random.randint(10, size  = self.shape)\n",
    "        \n",
    "    def _generate_payoffs(self):\n",
    "        return np.random.randint(-10, 10, size = self.shape)\n",
    "\n",
    "    def _generate_random_game(self):        \n",
    "        self.shape = (random.randint(3, 5), random.randint(3, 5))        \n",
    "        self.payoffs = self._generate_payoffs()\n",
    "        self.costs = self._generate_costs()\n",
    "        self.condition_chances = self._generate_probabilities()\n",
    "    \n",
    "    def _generate_game_data(self):        \n",
    "        self.rows = self.shape[0]\n",
    "        self.columns = self.shape[1]\n",
    "        self.payoff_regret = self._calculate_payoff_regret()\n",
    "        self.cost_regret = self._calculate_cost_regret()\n",
    "\n",
    "    def _calculate_payoff_regret(self):\n",
    "        maximum_payoffs_per_column = np.amax(self.payoffs, axis = 0)                        \n",
    "        return np.reshape([maximum_payoffs_per_column - gain for gain in self.payoffs], self.shape)\n",
    "\n",
    "    def _calculate_cost_regret(self):\n",
    "        minimum_costs_per_column = np.amin(self.costs, axis = 0)                        \n",
    "        return np.reshape([cost - minimum_costs_per_column for cost in self.costs], self.shape)\n",
    "\n",
    "    def _generate_probabilities(self):\n",
    "        list_of_random_floats = np.random.random(self.shape[1])\n",
    "        sum_of_values = list_of_random_floats.sum()        \n",
    "        normalized_values = list_of_random_floats / sum_of_values        \n",
    "        return normalized_values\n",
    "\n",
    "    def _is_probabilities_correct(self, probabilities : np.ndarray):        \n",
    "        return math.isclose(probabilities.sum(), 1, abs_tol=10**-4) and len(probabilities) == self.columns\n",
    "    \n",
    "    def summary(self):\n",
    "        print(\"Game Stats:\")     \n",
    "        self.print_probabilities()\n",
    "        self.print_payoffs()      \n",
    "        self.print_payoff_regret()\n",
    "        self.print_costs()     \n",
    "        self.print_cost_regret()                \n",
    "\n",
    "    def print_payoffs(self):\n",
    "        print(f\"Payoffs: \\n{self.payoffs}\")\n",
    "    \n",
    "    def print_payoff_regret(self):\n",
    "        print(f\"Payoff Regret:\\n{self.payoff_regret}\")\n",
    "    \n",
    "    def print_costs(self):\n",
    "        print(f\"Costs: \\n{self.costs}\")\n",
    "\n",
    "    def print_cost_regret(self):\n",
    "        print(f\"Cost Regret:\\n{self.cost_regret}\")\n",
    "    \n",
    "    def print_probabilities(self):\n",
    "        print(f\"Probabilities:\\n{self.condition_chances}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Criterion(ABC):\n",
    "    def get_name(self) -> str:\n",
    "        return re.sub(r\"\\B([A-Z])\", r\" \\1\", \"%s\" % type(self).__name__)               \n",
    "    \n",
    "    def _get_rows(self, m: np.ndarray):\n",
    "        return m.shape[0]        \n",
    "\n",
    "    def _get_columns(self, m: np.ndarray):\n",
    "        return m.shape[1]\n",
    "    \n",
    "    def _is_dimensions_equal_two(m: np.ndarray):\n",
    "        return len(m.shape) == 2\n",
    "\n",
    "    def _get_equal_results(self, scores, best_score):\n",
    "        return np.argwhere(scores == best_score).flatten()\n",
    "\n",
    "    def _get_close_results(self, scores, best_score, abs_tol=10**-4):\n",
    "        return np.argwhere(np.isclose(scores, best_score, atol=abs_tol)).flatten()    \n",
    "\n",
    "    def _is_probabilities_correct(self, probabilities : np.ndarray):        \n",
    "        return math.isclose(probabilities.sum(), 1, abs_tol=10**-4)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PayoffCriterion(Criterion):\n",
    "    @abstractmethod    \n",
    "    def get_payoff_optimal_choices(self, payoffs: np.ndarray, probabilities: np.ndarray = None):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CostCriterion(Criterion):\n",
    "    @abstractmethod    \n",
    "    def get_cost_optimal_choices(self, costs: np.ndarray, probabilities: np.ndarray = None):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegretCriterion(PayoffCriterion, CostCriterion):\n",
    "    @abstractmethod    \n",
    "    def get_regret_optimal_choices(self, regrets: np.ndarray, probabilities: np.ndarray = None):\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def calculate_payoff_regret(self, payoffs: np.ndarray):\n",
    "        maxs = np.amax(payoffs, axis = 0) # per columns\n",
    "        return np.reshape([maxs - payoff for payoff in payoffs], payoffs.shape)\n",
    "\n",
    "    def calculate_cost_regret(self, costs: np.ndarray):\n",
    "        mins = np.amin(costs, axis = 0) # per columns\n",
    "        return np.reshape([cost - mins for cost in costs], costs.shape)\n",
    "\n",
    "    def get_payoff_optimal_choices(self, payoffs: np.ndarray, probabilities: np.ndarray = None):\n",
    "        regrets = self.calculate_payoff_regret(payoffs)\n",
    "        return self.get_regret_optimal_choices(regrets, probabilities)\n",
    "\n",
    "    def get_cost_optimal_choices(self, costs: np.ndarray, probabilities: np.ndarray = None):\n",
    "        regrets = self.calculate_cost_regret(costs)\n",
    "        return self.get_regret_optimal_choices(regrets, probabilities)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunctionsResearchCriterion(PayoffCriterion):\n",
    "    def __init__(self):                      \n",
    "        super().__init__() \n",
    "        self.coefficients = np.array([])  \n",
    "        self._ylabel = \"f(i, λ)\"      \n",
    "\n",
    "    @abstractmethod\n",
    "    def function(self, *args):\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _get_coefficients(self, payoffs: np.ndarray, probabilities: np.ndarray = None):\n",
    "        raise NotImplementedError() \n",
    "    \n",
    "    def get_payoff_optimal_choices(self, payoffs: np.ndarray, probabilities: np.ndarray = None):                                        \n",
    "        self.coefficients = self._get_coefficients(payoffs, probabilities)\n",
    "        count = np.zeros(shape = self._get_rows(payoffs), dtype=np.int32)                     \n",
    "        # could've just compare coefficients or solve analytically\n",
    "        points = np.linspace(0, 1, 1000)\n",
    "        for p in points:            \n",
    "            fn_results = [self.function(p, *c) for c in self.coefficients]\n",
    "            max_fn_result = np.amax(fn_results)\n",
    "            idx = self._get_equal_results(fn_results, max_fn_result)\n",
    "            \n",
    "            for index in idx:\n",
    "                count[index] += 1\n",
    "                  \n",
    "        max_count = np.amax(count)\n",
    "        return self._get_equal_results(count, max_count)\n",
    "        \n",
    "    @abstractmethod\n",
    "    def _get_tex_fn(self, *args) -> str:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def print_functions(self):                \n",
    "        for index, c in enumerate(self.coefficients):\n",
    "            if IN_COLAB:\n",
    "                print(f\"Strategy №{index + 1} function:\")\n",
    "                display(Latex(f\"${self._get_tex_fn(*c)}$\"))   \n",
    "            else:\n",
    "                display(Latex(f\"Strategy №{index + 1} function: ${self._get_tex_fn(*c)}$\"))   \n",
    "    \n",
    "    def plot(self):\n",
    "        fig = plt.figure()\n",
    "        ax = plt.axes()        \n",
    "        plt.title(self.get_name())\n",
    "        plt.xlabel(\"λ\")\n",
    "        plt.ylabel(self._ylabel)              \n",
    "        l = np.linspace(0, 1, 2)\n",
    "        for index, c in enumerate(self.coefficients):        \n",
    "            plt.plot(l, self.function(l, *c), color=np.random.random(3), label= \"Strategy №%d\" % (index + 1)) \n",
    "        plt.legend()\n",
    "        plt.draw()\n",
    "          \n",
    "    def summary(self):        \n",
    "        self.print_functions()\n",
    "        self.plot()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CriteriaTester():\n",
    "    def test_payoff(self, criterion: Criterion, game: Game):        \n",
    "        if isinstance(criterion, PayoffCriterion):\n",
    "            result =criterion.get_payoff_optimal_choices(game.payoffs, game.condition_chances)\n",
    "            self.print_result(criterion, result)\n",
    "\n",
    "    def test_cost(self, criterion: Criterion, game: Game):        \n",
    "        if isinstance(criterion, CostCriterion):\n",
    "            result = criterion.get_cost_optimal_choices(game.costs, game.condition_chances)\n",
    "            self.print_result(criterion, result)\n",
    "\n",
    "    def print_result(self, criterion: Criterion, choices) -> str:        \n",
    "        if len(choices) > 1:\n",
    "            print(f\"According to {criterion.get_name()}, the optimal strategies are №{choices + 1}.\")\n",
    "        else:\n",
    "            print(f\"According to {criterion.get_name()}, the optimal strategy is №{choices[0] + 1}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameCriteriaPicksStats():\n",
    "    def __init__(self, game: Game) -> None:\n",
    "        self.criteria = []\n",
    "        self.game = game\n",
    "        pass\n",
    "\n",
    "    def add_criterion(self, criterion: Criterion):\n",
    "        self.criteria.append(criterion)            \n",
    "\n",
    "    def get_payoff_choices(self):        \n",
    "        choices = []\n",
    "        for criterion in self.criteria:\n",
    "            if isinstance(criterion, PayoffCriterion):\n",
    "                choices += (criterion.get_payoff_optimal_choices(self.game.payoffs, self.game.condition_chances) + 1).tolist()\n",
    "        return choices\n",
    "            \n",
    "    def get_cost_choices(self):        \n",
    "        choices = []\n",
    "        for criterion in self.criteria:\n",
    "            if isinstance(criterion, CostCriterion):\n",
    "                choices += (criterion.get_cost_optimal_choices(self.game.costs, self.game.condition_chances) + 1).tolist()\n",
    "        return choices\n",
    "\n",
    "    def payoff_hist(self):\n",
    "        choices = self.get_payoff_choices()\n",
    "        self.hist(choices, \"Strategy picks by payoff criteria\")\n",
    "\n",
    "    def cost_hist(self):\n",
    "        choices = self.get_cost_choices()\n",
    "        self.hist(choices, \"Strategy picks by cost criteria\")\n",
    "\n",
    "    def hist(self, choices, title = \"Strategy picks\"):\n",
    "        # Set up the bins centered on the integers, i.e. -0.5, 0.5, 1,5, 2.5, ... up to max(data) + 1.5. Then substract -0.5 to eliminate the extra bin at the end.\n",
    "        bins = np.arange(1, self.game.rows + 1.5) - 0.5\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        counts, edges, bars = ax.hist(choices, bins, density=False, label=\"Picks\") # density=True would make frequencies\n",
    "        ax.set_xticks(bins + 0.5)        \n",
    "    \n",
    "        #plt.bar_label(bars)\n",
    "        plt.ylabel('Number of Picks')\n",
    "        plt.xlabel('Strategy Number');        \n",
    "        plt.legend(loc=\"upper left\")\n",
    "        plt.title(title)\n",
    "        \n",
    "    def summary(self):        \n",
    "        self.payoff_hist()\n",
    "        self.cost_hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criterion of Rationality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Laplace Criterion (Bayes' Criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\underset{i}{max} \\space \\frac{1}{n} \\sum_{j=1}^n p_{ij} \\space\\space\\space\\space (i \\in \\overline{1,m}, \\space j \\in \\overline{1,n})$$\n",
    "$$\\underset{i}{min} \\space \\frac{1}{n} \\sum_{j=1}^n c_{ij} \\space\\space\\space\\space (i \\in \\overline{1,m}, \\space j \\in \\overline{1,n})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaplaceCriterion(PayoffCriterion, CostCriterion):\n",
    "    def get_payoff_optimal_choices(self, payoffs: np.ndarray, probabilities: np.ndarray = None):        \n",
    "        sums = self._calculate_sums(payoffs)\n",
    "        max_expected_payoff = np.amax(sums)        \n",
    "        return self._get_equal_results(sums, max_expected_payoff)\n",
    "    \n",
    "    def get_cost_optimal_choices(self, costs: np.ndarray, probabilities: np.ndarray = None):        \n",
    "        sums = self._calculate_sums(costs)\n",
    "        min_expected_cost = np.amin(sums)        \n",
    "        return self._get_equal_results(sums, min_expected_cost)\n",
    "        \n",
    "    def _calculate_sums(self, m: np.ndarray):\n",
    "        return np.array([np.sum(row) for row in m]) / self._get_columns(m)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum Expected Payoff Criterion (Expected Utility Maximization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\underset{i}{max} \\sum_{j=1}^n p_{ij} y_{j} \\space (i \\in \\overline{1,m})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaximumExpectedPayoffCriterion(PayoffCriterion):\n",
    "    def get_payoff_optimal_choices(self, payoffs: np.ndarray, probabilities: np.ndarray):          \n",
    "        sums = [np.sum(payoff * probabilities) for payoff in payoffs]\n",
    "        maxsum = np.amax(sums)        \n",
    "        return self._get_equal_results(sums, maxsum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimum Expected Cost Criterion (Expected Cost Minimization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\underset{i}{min} \\sum_{j=1}^n c_{ij} y_{j} \\space (i \\in \\overline{1,m})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaximumExpectedCostCriterion(CostCriterion):\n",
    "    def get_cost_optimal_choices(self, costs: np.ndarray, probabilities: np.ndarray = None):        \n",
    "        sums = [np.sum(cost * probabilities) for cost in costs]\n",
    "        minsum = np.amin(sums)        \n",
    "        return self._get_equal_results(sums, minsum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimum Expected Regret Criterion (Expected Regret Minimization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\underset{i}{min} \\sum_{j=1}^n r_{ij} y_{j} \\space (i \\in \\overline{1,m})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinimumExpectedRegretCriterion(RegretCriterion):\n",
    "    def get_regret_optimal_choices(self, regrets: np.ndarray, probabilities: np.ndarray):\n",
    "        sums = [np.sum(regret * probabilities) for regret in regrets]\n",
    "        minsum = np.amin(sums)      \n",
    "        return self._get_equal_results(sums, minsum)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criterion of Pessimism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wald Criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\underset{i}{max} \\cdot \\underset{j}{min} \\cdot p_{ij} \\space\\space\\space\\space (i \\in \\overline{1,m}, \\space j \\in \\overline{1,n})$$\n",
    "$$\\underset{i}{min} \\cdot \\underset{j}{max} \\cdot c_{ij} \\space\\space\\space\\space (i \\in \\overline{1,m}, \\space j \\in \\overline{1,n})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaldCriterion(PayoffCriterion, CostCriterion):\n",
    "    def get_payoff_optimal_choices(self, payoffs: np.ndarray, probabilities: np.ndarray = None):        \n",
    "        mins = np.amin(payoffs, axis = 1)        \n",
    "        maximin = np.amax(mins)        \n",
    "        return self._get_equal_results(mins, maximin)\n",
    "\n",
    "    def get_cost_optimal_choices(self, costs: np.ndarray, probabilities: np.ndarray = None):        \n",
    "        maxs = np.amax(costs, axis = 1)        \n",
    "        minimax = np.amin(maxs)        \n",
    "        return self._get_equal_results(maxs, minimax)             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Savage Criterion (Minimax Regret Criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\underset{i}{min} \\cdot \\underset{j}{max} \\cdot r_{ij} \\space\\space\\space\\space (i \\in \\overline{1,m}, \\space j \\in \\overline{1,n})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SavageCriterion(RegretCriterion):\n",
    "    def get_regret_optimal_choices(self, regrets: np.ndarray, probabilities: np.ndarray = None):\n",
    "        maxs = np.amax(regrets, axis = 1) # per rows\n",
    "        minimax = np.amin(maxs)        \n",
    "        return self._get_equal_results(maxs, minimax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criterion of Optimism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximax Criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\underset{i}{max} \\cdot \\underset{j}{max} \\cdot p_{ij} \\space\\space\\space\\space (i \\in \\overline{1,m}, \\space j \\in \\overline{1,n})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaximaxCriterion(PayoffCriterion):\n",
    "    def get_payoff_optimal_choices(self, payoffs: np.ndarray, probabilities: np.ndarray = None):        \n",
    "        maxs = np.amax(payoffs, axis = 1)\n",
    "        maximax = np.amax(maxs)        \n",
    "        return self._get_equal_results(maxs, maximax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimin Criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\underset{i}{min} \\cdot \\underset{j}{min} \\cdot c_{ij} \\space\\space\\space\\space (i \\in \\overline{1,m}, \\space j \\in \\overline{1,n})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniminCriterion(CostCriterion):\n",
    "    def get_cost_optimal_choices(self, costs: np.ndarray, probabilities: np.ndarray = None):        \n",
    "        mins = np.amin(costs, axis = 1)\n",
    "        minimin = np.amin(mins)   \n",
    "        return self._get_equal_results(mins, minimin) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criterion of Realism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hurwicz Criterion (Criterion of Realism)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$g(i, \\lambda) = \\lambda \\space \\underset{j}{min} \\space p_{ij} + (1-\\lambda) \\space \\underset{j}{max} \\space p_{ij} \\space \\space (i \\in \\overline{1,m})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HurwiczCriterion(FunctionsResearchCriterion):\n",
    "    def function(self, l, min, max):\n",
    "        return l * min + (1 - l) * max\n",
    "        \n",
    "    def _get_coefficients(self, payoffs: np.ndarray, probabilities: np.ndarray = None):        \n",
    "        return [(np.min(payoff), np.max(payoff)) for payoff in payoffs]\n",
    "        \n",
    "    def _get_tex_fn(self, min, max) -> str:        \n",
    "        return f\"g(i,\\lambda)={min}\\lambda+{max}(1-\\lambda)\" if max >= 0 else f\"g(i,\\lambda)={min}\\lambda{max}(1-\\lambda)\"                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hodges–Lehmann Criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$h(i, \\lambda) = \\lambda \\space \\underset{j}{min} \\space p_{ij} + (1-\\lambda) \\space \\sum_{j=1}^n \\space p_{ij} \\space y_{j} \\space \\space (i \\in \\overline{1,m})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HodgesLehmannCriterion(FunctionsResearchCriterion):\n",
    "    def function(self, l, min, sum):\n",
    "        return l * min + (1 - l) * sum\n",
    "\n",
    "    def get_payoff_optimal_choices(self, payoffs: np.ndarray, probabilities: np.ndarray):\n",
    "        return super().get_payoff_optimal_choices(payoffs, probabilities)\n",
    "\n",
    "    def _get_coefficients(self, payoffs: np.ndarray, probabilities: np.ndarray):        \n",
    "        return [(np.min(payoff), np.sum(payoff * probabilities)) for payoff in payoffs]\n",
    "                            \n",
    "    def _get_tex_fn(self, min, sum) -> str:        \n",
    "        return f\"h(i,\\lambda)={min}\\lambda+{sum}(1-\\lambda)\" if sum >= 0 else f\"h(i,\\lambda)={min}\\lambda{sum}(1-\\lambda)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hodges-Lehmann Criterion (Modification 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$u(i, \\lambda) = \\lambda \\space \\underset{j}{max} \\space p_{ij} + (1-\\lambda) \\space \\sum_{j=1}^n \\space p_{ij} \\space y_{j} \\space \\space (i \\in \\overline{1,m})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HodgesLehmannCriterion_Modification1(FunctionsResearchCriterion):\n",
    "    def function(self, l, max, sum):\n",
    "        return l * max + (1 - l) * sum\n",
    "\n",
    "    def _get_coefficients(self, payoffs: np.ndarray, probabilities: np.ndarray):\n",
    "        return [(np.max(payoff), np.sum(payoff * probabilities)) for payoff in payoffs]\n",
    "                            \n",
    "    def _get_tex_fn(self, max, sum) -> str:        \n",
    "        return f\"h(i,\\lambda)={max}\\lambda+{sum}(1-\\lambda)\" if sum >= 0 else f\"h(i,\\lambda)={max}\\lambda{sum}(1-\\lambda)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hodges-Lehmann Criterion (Modification 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$v(i, \\space \\lambda, \\space \\mu) = \\lambda \\space \\underset{j}{min} \\space p_{ij} + \\mu \\space \\underset{j}{max} \\space p_{ij} + (1-\\lambda-\\mu) \\space \\sum_{j=1}^n \\space p_{ij} \\space y_{j}\\space \\space (i \\in \\overline{1,m})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HodgeLemanCriterion_Modification2(FunctionsResearchCriterion):\n",
    "    def _get_coefficients(self, payoffs: np.ndarray, probabilities: np.ndarray):\n",
    "        return [(np.min(payoff), np.max(payoff), np.sum(payoff * probabilities)) for payoff in payoffs]\n",
    "                \n",
    "    def function(self, l, u, min, max, sum):\n",
    "        return (l * min) + (u * max) + (1 - l - u) * sum\n",
    "\n",
    "    def get_payoff_optimal_choices(self, payoffs: np.ndarray, probabilities: np.ndarray):        \n",
    "        self.coefficients = self._get_coefficients(payoffs, probabilities)\n",
    "        count = np.zeros(shape = self._get_rows(payoffs), dtype=np.int32)\n",
    "        _l = np.linspace(0, 1, 100)\n",
    "        _u = np.linspace(0, 1, 100)\n",
    "        l = []\n",
    "        u = []                  \n",
    "        for lp in _l:            \n",
    "            for up in _u:\n",
    "                if lp + up < 1:\n",
    "                    l.append(lp)\n",
    "                    u.append(up)\n",
    "                    fns_results = [self.function(lp, up, *c) for c in self.coefficients]                    \n",
    "                    max_fn_result = np.amax(fns_results)\n",
    "                    idx = self._get_equal_results(fns_results, max_fn_result)\n",
    "                    for index in idx:\n",
    "                        count[index] += 1\n",
    "        \n",
    "        self.l = np.array(l)\n",
    "        self.u = np.array(u)                                                         \n",
    "        max_count = np.amax(count)\n",
    "        return self._get_equal_results(count, max_count)\n",
    "\n",
    "    def _get_tex_fn(self, min, max, sum) -> str:\n",
    "        if max >= 0 and sum >= 0:\n",
    "            return f\"v(i,\\space\\lambda,\\space\\mu)={min}\\lambda+{max}\\mu+{sum}(1-\\lambda-\\mu)\"\n",
    "        elif max >= 0:\n",
    "            return f\"v(i,\\space\\lambda,\\space\\mu)={min}\\lambda+{max}\\mu{sum}(1-\\lambda-\\mu)\"\n",
    "        else:\n",
    "            return f\"v(i,\\space\\lambda,\\space\\mu)={min}\\lambda{max}\\mu{sum}(1-\\lambda-\\mu)\"\n",
    "\n",
    "    def plot(self):        \n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        plt.title(self.get_name())\n",
    "        ax.set_xlabel('l')\n",
    "        ax.set_ylabel('u')\n",
    "        ax.set_zlabel('u(i, λ, μ)')\n",
    "                                                  \n",
    "        for index, c in enumerate(self.coefficients):                                                      \n",
    "            ax.plot(self.l, self.u, self.function(self.l, self.u, *c), label= \"Strategy №%d\" % (index + 1))            \n",
    "        \n",
    "        plt.legend()\n",
    "        ax.view_init(10, 30)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplace = LaplaceCriterion()\n",
    "maximax = MaximaxCriterion()\n",
    "minimin = MiniminCriterion()\n",
    "wald = WaldCriterion()\n",
    "savage = SavageCriterion()\n",
    "max_utility = MaximumExpectedPayoffCriterion()\n",
    "min_cost = MaximumExpectedCostCriterion()\n",
    "min_risk = MinimumExpectedRegretCriterion()\n",
    "hurwicz = HurwiczCriterion()\n",
    "hodge_leman = HodgesLehmannCriterion()\n",
    "hodge_leman_m1 = HodgesLehmannCriterion_Modification1()\n",
    "hodge_leman_m2 = HodgeLemanCriterion_Modification2()\n",
    "\n",
    "criteria = [laplace, max_utility, min_cost, min_risk, wald, savage, maximax, minimin, hurwicz, hodge_leman, hodge_leman_m1, hodge_leman_m2]\n",
    "\n",
    "game = Game()\n",
    "game.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = CriteriaTester()\n",
    "for criterion in criteria:\n",
    "    tester.test_payoff(criterion, game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for criterion in criteria:\n",
    "    tester.test_cost(criterion, game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hurwicz.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hodge_leman.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hodge_leman_m1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hodge_leman_m2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = GameCriteriaPicksStats(game)\n",
    "\n",
    "for criterion in criteria:\n",
    "    stats.add_criterion(criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3606536e489b33f8869ba4c3a9d0500bfb79660587eb656f3eb62f46c0726603"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
